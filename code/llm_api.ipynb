{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "55207dc8-0fcc-4ada-8b3e-80bb98df82c1",
      "metadata": {
        "id": "55207dc8-0fcc-4ada-8b3e-80bb98df82c1"
      },
      "source": [
        "# Gemini Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad6bf125-d5df-4d01-ad67-37db5b70e85b",
      "metadata": {
        "id": "ad6bf125-d5df-4d01-ad67-37db5b70e85b",
        "outputId": "442866e8-b190-4b97-fd0c-e221ef5a1330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
          ]
        }
      ],
      "source": [
        "# !pip install google-generativeai==0.8.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5c56369-5d21-4b0d-aa74-8b09d190e857",
      "metadata": {
        "id": "a5c56369-5d21-4b0d-aa74-8b09d190e857"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "from utils import load_prompts\n",
        "prompts = load_prompts(\"prompts.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d203c836-5e1e-4145-a282-686e4aee5f68",
      "metadata": {
        "id": "d203c836-5e1e-4145-a282-686e4aee5f68",
        "outputId": "0304069a-3bb1-46c2-bb98-33c69f408107"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'system': {'general': 'You are an expert at Natural Language Inference (NLI). Your task is to analyze two pieces of text - a premise and a hypothesis - and classify them into NEUTRAL, ENTAILMENT, or CONTRADICTION.'}, 'user': {'general': 'premise: {PREMISE_HERE}, hypothesis: {HYPOTHESIS_HERE}.', 'json_mode': \"Generate the classification result in JSON with the key: 'result': str (NEUTRAL, ENTAILMENT, or CONTRADICTION)\", 'few': 'USER: premise: {PREMISE_1}, hypothesis: {HYPOTHESIS_1}.\\nMODEL: {RESULT_1}\\nUSER: premise: {PREMISE_2}, hypothesis: {HYPOTHESIS_2}.\\nMODEL: {RESULT_2}\\nUSER: premise: {PREMISE_3}, hypothesis: {HYPOTHESIS_3}.\\nMODEL:'}, 'mutual': {'few_hint': 'Please first check the following examples.'}}\n"
          ]
        }
      ],
      "source": [
        "print(prompts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c10e382f-a1ca-47db-9711-5ae8ce78ef7a",
      "metadata": {
        "id": "c10e382f-a1ca-47db-9711-5ae8ce78ef7a"
      },
      "outputs": [],
      "source": [
        "MY_GOOGLE_API_KEY = \"MY_GOOGLE_API_KEY\"\n",
        "genai.configure(api_key=MY_GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34334b7d-32f2-4cc5-bb6d-f9d240d2d695",
      "metadata": {
        "id": "34334b7d-32f2-4cc5-bb6d-f9d240d2d695"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"gemini-1.5-pro\"\n",
        "TEMPERATURE = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be4fb61a-6897-4afa-aada-13563e1decaa",
      "metadata": {
        "id": "be4fb61a-6897-4afa-aada-13563e1decaa"
      },
      "source": [
        "## Example for Classification\n",
        "- Dataset: SemEval 2014 Task1-2 (3-class classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dae8347-bcc7-48d3-8cbf-a5f74d3bc7c7",
      "metadata": {
        "id": "0dae8347-bcc7-48d3-8cbf-a5f74d3bc7c7"
      },
      "outputs": [],
      "source": [
        "inputs = {\n",
        "    \"premise\": \"A group of kids is playing in a yard and an old man is standing in the background\",\n",
        "    \"hypothesis\": \"A group of boys in a yard is playing and a man is standing in the background\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bcbf02e-6581-48e6-a38f-c51718660b42",
      "metadata": {
        "id": "8bcbf02e-6581-48e6-a38f-c51718660b42"
      },
      "outputs": [],
      "source": [
        "system_prompt = prompts[\"system\"][\"general\"]\n",
        "user_prompt = prompts[\"user\"][\"general\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54ae7de1-63cb-45ee-a2bb-d4b44a407411",
      "metadata": {
        "id": "54ae7de1-63cb-45ee-a2bb-d4b44a407411",
        "outputId": "a818b37f-3d76-434d-8c8c-f08d242ce4b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an expert at Natural Language Inference (NLI). Your task is to analyze two pieces of text - a premise and a hypothesis - and classify them into NEUTRAL, ENTAILMENT, or CONTRADICTION.\n",
            "premise: {PREMISE_HERE}, hypothesis: {HYPOTHESIS_HERE}.\n"
          ]
        }
      ],
      "source": [
        "print(system_prompt)\n",
        "print(user_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a48c773-8d2d-438b-88c0-2ae5d07d1f56",
      "metadata": {
        "id": "5a48c773-8d2d-438b-88c0-2ae5d07d1f56"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(\n",
        "    MODEL_NAME,\n",
        "    generation_config={\"temperature\": TEMPERATURE},\n",
        "    system_instruction=system_prompt,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2bec27e-f1a7-406f-9232-ac3d494f3de6",
      "metadata": {
        "id": "b2bec27e-f1a7-406f-9232-ac3d494f3de6",
        "outputId": "8651dc5b-6f05-4338-b11e-e9b6902a1c24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "premise: A group of kids is playing in a yard and an old man is standing in the background, hypothesis: A group of boys in a yard is playing and a man is standing in the background.\n"
          ]
        }
      ],
      "source": [
        "cur_user_prompt = user_prompt.format(\n",
        "    PREMISE_HERE=inputs[\"premise\"],\n",
        "    HYPOTHESIS_HERE=inputs[\"hypothesis\"]\n",
        ")\n",
        "print(cur_user_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2a39d10-1317-47a4-b841-0e11f413f817",
      "metadata": {
        "id": "d2a39d10-1317-47a4-b841-0e11f413f817"
      },
      "outputs": [],
      "source": [
        "response = model.generate_content(cur_user_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e9c211a-e7eb-40b1-88d7-26ee59951f51",
      "metadata": {
        "id": "2e9c211a-e7eb-40b1-88d7-26ee59951f51",
        "outputId": "e06d3c18-48f0-4cdf-c67c-ecd6a10c9785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NEUTRAL.  The premise states \"kids,\" which could include girls. The hypothesis specifies \"boys.\"  The premise says \"old man,\" while the hypothesis just says \"man.\"  While an old man *is* a man, the hypothesis doesn't require the man to be old.  Therefore, the hypothesis is neither entailed nor contradicted by the premise.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46110d8f-a78e-47d8-9e68-884bb18f9f71",
      "metadata": {
        "id": "46110d8f-a78e-47d8-9e68-884bb18f9f71",
        "outputId": "92e483ec-f516-40c9-e251-6bfbdec50949"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of input tokens: 173\n"
          ]
        }
      ],
      "source": [
        "num_sys_tokens = str(model.count_tokens(system_prompt)).split(\": \")[1].strip()\n",
        "num_usr_tokens = str(model.count_tokens(cur_user_prompt)).split(\": \")[1].strip()\n",
        "num_input_tokens = int(num_sys_tokens) + int(num_usr_tokens)\n",
        "print(f\"Num of input tokens: {num_input_tokens}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5abb7ead-f79b-46d5-b98b-eaace44a7c59",
      "metadata": {
        "id": "5abb7ead-f79b-46d5-b98b-eaace44a7c59",
        "outputId": "c039a1a1-3d87-4c80-bb1e-32c9705415f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of output tokens 119\n"
          ]
        }
      ],
      "source": [
        "num_output_tokens = str(model.count_tokens(response.text)).split(\": \")[1].strip()\n",
        "print(f\"Num of output tokens {num_output_tokens}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3aae09fa-ed4c-4c13-946c-3222f94dd014",
      "metadata": {
        "id": "3aae09fa-ed4c-4c13-946c-3222f94dd014"
      },
      "source": [
        "### Generate structured output in JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc69ea10-19e1-4633-90f3-dedcdc46fd62",
      "metadata": {
        "id": "cc69ea10-19e1-4633-90f3-dedcdc46fd62"
      },
      "outputs": [],
      "source": [
        "user_prompt_json = prompts[\"user\"][\"general\"] + \" \" + prompts[\"user\"][\"json_mode\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5b741b2-5500-46d7-a480-db14432b6678",
      "metadata": {
        "id": "a5b741b2-5500-46d7-a480-db14432b6678",
        "outputId": "8707cb8f-edae-4005-832e-7bc61b1f2e59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "premise: A group of kids is playing in a yard and an old man is standing in the background, hypothesis: A group of boys in a yard is playing and a man is standing in the background. Generate the classification result in JSON with the key: 'result': str (NEUTRAL, ENTAILMENT, or CONTRADICTION)\n"
          ]
        }
      ],
      "source": [
        "cur_user_prompt = user_prompt_json.format(\n",
        "    PREMISE_HERE=inputs[\"premise\"],\n",
        "    HYPOTHESIS_HERE=inputs[\"hypothesis\"]\n",
        ")\n",
        "print(cur_user_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3307a22c-2413-400a-ab61-c9af4cd6fb82",
      "metadata": {
        "id": "3307a22c-2413-400a-ab61-c9af4cd6fb82"
      },
      "outputs": [],
      "source": [
        "response = model.generate_content(\n",
        "    cur_user_prompt,\n",
        "    generation_config={\n",
        "        \"response_mime_type\": \"application/json\",\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72f1bd25-faf5-4087-a37a-5cb595c2e591",
      "metadata": {
        "id": "72f1bd25-faf5-4087-a37a-5cb595c2e591",
        "outputId": "8ddee1d3-ac22-42e1-d605-a44ad48d37f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d57965af-fd26-4f4f-a5b4-68c3e3d1d7ca",
      "metadata": {
        "id": "d57965af-fd26-4f4f-a5b4-68c3e3d1d7ca",
        "outputId": "f0dd2a45-b13b-4976-c422-a662a5d31d05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "{'result': 'NEUTRAL'}\n"
          ]
        }
      ],
      "source": [
        "result_json = json.loads(response.text)\n",
        "print(type(result_json))\n",
        "print(result_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba5bfae9-723a-48a4-b52c-f3c740b55438",
      "metadata": {
        "id": "ba5bfae9-723a-48a4-b52c-f3c740b55438"
      },
      "source": [
        "### Few-shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f705b761-cc2e-4e23-a956-644341f1ad1c",
      "metadata": {
        "id": "f705b761-cc2e-4e23-a956-644341f1ad1c"
      },
      "outputs": [],
      "source": [
        "fs_user_prompt = prompts[\"user\"][\"few\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6275f3b6-b39a-4920-9823-c1ea70e12253",
      "metadata": {
        "id": "6275f3b6-b39a-4920-9823-c1ea70e12253",
        "outputId": "e063e415-5cfb-43e9-8204-0e372aaa1666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USER: premise: A group of kids is playing in a yard and an old man is standing in the background, hypothesis: A group of boys in a yard is playing and a man is standing in the background.\n",
            "MODEL: {'result': 'NEUTRAL'}\n",
            "USER: premise: A man, a woman and two girls are walking on the beach, hypothesis: A group of people is on a beach.\n",
            "MODEL: {'result': 'ENTAILMENT'}\n",
            "USER: premise: Two teams are competing in a football match, hypothesis: Two groups of people are playing football.\n",
            "MODEL:\n"
          ]
        }
      ],
      "source": [
        "cur_fs_user_prompt = fs_user_prompt.format(\n",
        "    PREMISE_1=\"A group of kids is playing in a yard and an old man is standing in the background\",\n",
        "    HYPOTHESIS_1=\"A group of boys in a yard is playing and a man is standing in the background\",\n",
        "    RESULT_1=\"{'result': 'NEUTRAL'}\",\n",
        "    PREMISE_2=\"A man, a woman and two girls are walking on the beach\",\n",
        "    HYPOTHESIS_2=\"A group of people is on a beach\",\n",
        "    RESULT_2=\"{'result': 'ENTAILMENT'}\",\n",
        "    PREMISE_3=\"Two teams are competing in a football match\",\n",
        "    HYPOTHESIS_3=\"Two groups of people are playing football\",\n",
        ")\n",
        "print(cur_fs_user_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb495bf0-5ee1-4e6e-b1e0-f050b08a7062",
      "metadata": {
        "id": "cb495bf0-5ee1-4e6e-b1e0-f050b08a7062",
        "outputId": "6536bc0a-cf13-4214-bf01-ac918efae04a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an expert at Natural Language Inference (NLI). Your task is to analyze two pieces of text - a premise and a hypothesis - and classify them into NEUTRAL, ENTAILMENT, or CONTRADICTION. Please first check the following examples.\n"
          ]
        }
      ],
      "source": [
        "fs_system_prompt = prompts[\"system\"][\"general\"] + \" \" + prompts[\"mutual\"][\"few_hint\"]\n",
        "print(fs_system_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf10cd01-2ceb-4a4a-b22e-f2ce6defbbe0",
      "metadata": {
        "id": "bf10cd01-2ceb-4a4a-b22e-f2ce6defbbe0"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(\n",
        "    MODEL_NAME,\n",
        "    generation_config={\"temperature\": TEMPERATURE},\n",
        "    system_instruction=fs_system_prompt,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4e2783f-1b02-4209-abfc-f5b74713f1e3",
      "metadata": {
        "id": "e4e2783f-1b02-4209-abfc-f5b74713f1e3"
      },
      "outputs": [],
      "source": [
        "response = model.generate_content(\n",
        "    cur_fs_user_prompt,\n",
        "    generation_config={\n",
        "        \"response_mime_type\": \"application/json\",\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1034be34-c78d-4681-a8bd-72106ff214c1",
      "metadata": {
        "id": "1034be34-c78d-4681-a8bd-72106ff214c1",
        "outputId": "f19e0564-8a15-4642-f7fe-4fa11d938c7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'result': 'ENTAILMENT'}\n"
          ]
        }
      ],
      "source": [
        "result_json = json.loads(response.text)\n",
        "print(result_json)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e00c92c-31fb-4a4d-8a01-2ee20f86164e",
      "metadata": {
        "id": "2e00c92c-31fb-4a4d-8a01-2ee20f86164e"
      },
      "source": [
        "## Example for Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59b1573a-6ec3-4c67-bd6f-c19cbd1fe78b",
      "metadata": {
        "id": "59b1573a-6ec3-4c67-bd6f-c19cbd1fe78b"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"你是個中文文本摘要的專家，現在請你對一篇輸入的文章進行摘要。\"\"\"\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    MODEL_NAME,\n",
        "    generation_config={\"temperature\": TEMPERATURE},\n",
        "    system_instruction=system_prompt,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f991b65-b6ce-4b1a-afa2-df876142e4a6",
      "metadata": {
        "id": "6f991b65-b6ce-4b1a-afa2-df876142e4a6"
      },
      "outputs": [],
      "source": [
        "input_source_txt = \"新华社受权于18日全文播发修改后的《中华人民共和国立法法》，修改后的立法法分为“总则”“法律”“行政法规”“地方性法规、自治条例和单行条例、规章”“适用与备案审查”“附则”等6章，共计105条。\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbdbbff9-f926-439b-a914-a293bc67c0d4",
      "metadata": {
        "id": "cbdbbff9-f926-439b-a914-a293bc67c0d4"
      },
      "outputs": [],
      "source": [
        "response = model.generate_content(input_source_txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "947de4bf-e71f-400e-bfdd-c5e17b6ce125",
      "metadata": {
        "id": "947de4bf-e71f-400e-bfdd-c5e17b6ce125",
        "outputId": "7429b1fd-e850-4ad0-ea8d-54763829bbae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'新修订的《中华人民共和国立法法》已正式发布，共六章105条，涵盖总则、法律、行政法规、地方性法规及规章、适用与备案审查以及附则等方面。\\n'"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2f6f7c1-6b71-437f-8e72-a72ea0f91192",
      "metadata": {
        "id": "a2f6f7c1-6b71-437f-8e72-a72ea0f91192"
      },
      "source": [
        "# Claude Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e202ca1-5a65-48de-8631-1afebfdfaaa3",
      "metadata": {
        "id": "8e202ca1-5a65-48de-8631-1afebfdfaaa3"
      },
      "outputs": [],
      "source": [
        "# !pip install anthropic==0.39.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a7b1a0f-9bf3-4967-af30-97d2f3b468f5",
      "metadata": {
        "id": "0a7b1a0f-9bf3-4967-af30-97d2f3b468f5"
      },
      "outputs": [],
      "source": [
        "import anthropic\n",
        "import json\n",
        "import re\n",
        "from utils import load_prompts\n",
        "prompts = load_prompts(\"prompts.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7c9aba8-bf01-40fa-9579-cfff450eefba",
      "metadata": {
        "id": "e7c9aba8-bf01-40fa-9579-cfff450eefba"
      },
      "outputs": [],
      "source": [
        "MY_anthropic_KEY = \"MY_anthropic_KEY\"\n",
        "client = anthropic.Anthropic(api_key=MY_anthropic_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b02cec37-1cc9-46ce-82de-387519362abc",
      "metadata": {
        "id": "b02cec37-1cc9-46ce-82de-387519362abc"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"claude-3-5-sonnet-20241022\"\n",
        "TEMPERATURE = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feb1b843-a039-4946-a56a-a65f5cff598e",
      "metadata": {
        "id": "feb1b843-a039-4946-a56a-a65f5cff598e"
      },
      "outputs": [],
      "source": [
        "system_prompt = prompts[\"system\"][\"general\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17f62cc8-1968-4033-a439-4d8abb83cea8",
      "metadata": {
        "id": "17f62cc8-1968-4033-a439-4d8abb83cea8"
      },
      "outputs": [],
      "source": [
        "user_prompt_json = prompts[\"user\"][\"general\"] + \" \" + prompts[\"user\"][\"json_mode\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07163c7b-84be-41db-93e0-fe30b4d91f07",
      "metadata": {
        "id": "07163c7b-84be-41db-93e0-fe30b4d91f07"
      },
      "outputs": [],
      "source": [
        "inputs = {\n",
        "    \"premise\": \"A group of kids is playing in a yard and an old man is standing in the background\",\n",
        "    \"hypothesis\": \"A group of boys in a yard is playing and a man is standing in the background\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45f8a768-2568-4fff-81e5-4d2f1d9cca4f",
      "metadata": {
        "id": "45f8a768-2568-4fff-81e5-4d2f1d9cca4f",
        "outputId": "8bb612dd-5c67-4a5f-8f7d-76b0351bd69a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "premise: A group of kids is playing in a yard and an old man is standing in the background, hypothesis: A group of boys in a yard is playing and a man is standing in the background. Generate the classification result in JSON with the key: 'result': str (NEUTRAL, ENTAILMENT, or CONTRADICTION)\n"
          ]
        }
      ],
      "source": [
        "cur_user_prompt = user_prompt_json.format(\n",
        "    PREMISE_HERE=inputs[\"premise\"],\n",
        "    HYPOTHESIS_HERE=inputs[\"hypothesis\"]\n",
        ")\n",
        "print(cur_user_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd6c8d8d-06c1-4a7f-806f-673c25830cdc",
      "metadata": {
        "id": "bd6c8d8d-06c1-4a7f-806f-673c25830cdc"
      },
      "outputs": [],
      "source": [
        "response = client.messages.create(\n",
        "    model=MODEL_NAME,\n",
        "    max_tokens=1000,\n",
        "    temperature=TEMPERATURE,\n",
        "    system=system_prompt,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": cur_user_prompt}],\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "result = response.content[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcfbdb5a-06d0-4f92-ba18-8ef5c19f8975",
      "metadata": {
        "id": "dcfbdb5a-06d0-4f92-ba18-8ef5c19f8975",
        "outputId": "e6299338-7cbe-4593-9834-473ae1947506"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Let me analyze this carefully:\\n\\n1. Premise mentions \"kids\" (gender-neutral) while hypothesis specifies \"boys\" (male)\\n2. Premise mentions \"old man\" while hypothesis just says \"man\"\\n3. Both texts agree on:\\n   - Group playing in a yard\\n   - Man standing in background\\n\\nSince the hypothesis specifies \"boys\" when the premise only mentions \"kids\" (which could be boys, girls, or mixed), and drops the \"old\" qualifier for the man, this is a NEUTRAL case. The hypothesis could be true, but it\\'s not necessarily entailed by the premise.\\n\\n{\\n    \"result\": \"NEUTRAL\"\\n}'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c034853-add6-424e-9b98-8825a0b8ea7b",
      "metadata": {
        "id": "3c034853-add6-424e-9b98-8825a0b8ea7b"
      },
      "outputs": [],
      "source": [
        "# Extract the JSON-like part of the response using regex to match a JSON object\n",
        "json_match = re.search(r\"\\{.*?\\}\", response.content[0].text, re.DOTALL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bf9db36-a4e7-48b2-8c4a-863a27af5616",
      "metadata": {
        "id": "1bf9db36-a4e7-48b2-8c4a-863a27af5616"
      },
      "outputs": [],
      "source": [
        "json_str = json_match.group(0)  # Extract the JSON string\n",
        "# Now parse the extracted JSON\n",
        "result = json.loads(json_str, strict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "231b74a4-1e35-4628-8939-096bf53b22b9",
      "metadata": {
        "id": "231b74a4-1e35-4628-8939-096bf53b22b9",
        "outputId": "bfd5de2b-935d-4827-ce68-439605b0ad64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'result': 'NEUTRAL'}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "333a982b-54eb-468a-a5ba-05c30a9e41f2",
      "metadata": {
        "id": "333a982b-54eb-468a-a5ba-05c30a9e41f2",
        "outputId": "e31559ce-9c98-402b-c3b9-c6f5d6e23d1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of input tokens 122\n",
            "Num of output tokens 149\n"
          ]
        }
      ],
      "source": [
        "print(f\"Num of input tokens {response.usage.input_tokens}\")\n",
        "print(f\"Num of output tokens {response.usage.output_tokens}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "580640e4-8a03-48a8-a66f-f9dae9e53939",
      "metadata": {
        "id": "580640e4-8a03-48a8-a66f-f9dae9e53939"
      },
      "source": [
        "## Few-shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21a84c8e-75f7-4df0-9ee5-9e2f66719e96",
      "metadata": {
        "id": "21a84c8e-75f7-4df0-9ee5-9e2f66719e96"
      },
      "outputs": [],
      "source": [
        "fs_system_prompt = prompts[\"system\"][\"general\"] + \" \" + prompts[\"mutual\"][\"few_hint\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f46281fc-54be-403e-9cde-30e257631c6f",
      "metadata": {
        "id": "f46281fc-54be-403e-9cde-30e257631c6f"
      },
      "outputs": [],
      "source": [
        "fs_user_prompt = prompts[\"user\"][\"few\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ce2fb20-c888-4dc9-8082-555ee922ec47",
      "metadata": {
        "id": "6ce2fb20-c888-4dc9-8082-555ee922ec47",
        "outputId": "71c2cb99-5603-4a4b-8395-1c89644bea63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USER: premise: A group of kids is playing in a yard and an old man is standing in the background, hypothesis: A group of boys in a yard is playing and a man is standing in the background.\n",
            "MODEL: {'result': 'NEUTRAL'}\n",
            "USER: premise: A man, a woman and two girls are walking on the beach, hypothesis: A group of people is on a beach.\n",
            "MODEL: {'result': 'ENTAILMENT'}\n",
            "USER: premise: Two teams are competing in a football match, hypothesis: Two groups of people are playing football.\n",
            "MODEL:\n"
          ]
        }
      ],
      "source": [
        "cur_fs_user_prompt = fs_user_prompt.format(\n",
        "    PREMISE_1=\"A group of kids is playing in a yard and an old man is standing in the background\",\n",
        "    HYPOTHESIS_1=\"A group of boys in a yard is playing and a man is standing in the background\",\n",
        "    RESULT_1=\"{'result': 'NEUTRAL'}\",\n",
        "    PREMISE_2=\"A man, a woman and two girls are walking on the beach\",\n",
        "    HYPOTHESIS_2=\"A group of people is on a beach\",\n",
        "    RESULT_2=\"{'result': 'ENTAILMENT'}\",\n",
        "    PREMISE_3=\"Two teams are competing in a football match\",\n",
        "    HYPOTHESIS_3=\"Two groups of people are playing football\",\n",
        ")\n",
        "print(cur_fs_user_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efd7064e-0b1d-4f10-b25a-1d6ccffacf2c",
      "metadata": {
        "id": "efd7064e-0b1d-4f10-b25a-1d6ccffacf2c"
      },
      "outputs": [],
      "source": [
        "response = client.messages.create(\n",
        "    model=MODEL_NAME,\n",
        "    max_tokens=1000,\n",
        "    temperature=TEMPERATURE,\n",
        "    system=fs_system_prompt,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [{\"type\": \"text\", \"text\": cur_user_prompt}],\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "result = response.content[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbc5a95c-89a8-40a2-ad8e-16b0e5cddeb1",
      "metadata": {
        "id": "bbc5a95c-89a8-40a2-ad8e-16b0e5cddeb1"
      },
      "outputs": [],
      "source": [
        "# Extract the JSON-like part of the response using regex to match a JSON object\n",
        "json_match = re.search(r\"\\{.*?\\}\", response.content[0].text, re.DOTALL)\n",
        "json_str = json_match.group(0)  # Extract the JSON string\n",
        "# Now parse the extracted JSON\n",
        "result = json.loads(json_str, strict=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a989aaab-bb13-4a37-8c05-cb22fd012699",
      "metadata": {
        "id": "a989aaab-bb13-4a37-8c05-cb22fd012699",
        "outputId": "932f021c-8de7-486b-ccb7-f415c5b62e97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'result': 'NEUTRAL'}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e32f1f50-ae8f-477e-88bc-c0ccc678aaa2",
      "metadata": {
        "id": "e32f1f50-ae8f-477e-88bc-c0ccc678aaa2"
      },
      "source": [
        "# OpenAI Usage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cx8OA50nFDJE",
      "metadata": {
        "id": "cx8OA50nFDJE"
      },
      "source": [
        "## Single-shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75d968cf-2066-46d1-b6fe-834ea2d9eedf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75d968cf-2066-46d1-b6fe-834ea2d9eedf",
        "outputId": "f836df58-45ef-48e5-d48e-d824d034fdd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==1.78.0\n",
            "  Downloading openai-1.78.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.78.0) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.78.0) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.78.0) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.78.0) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.78.0) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.78.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai==1.78.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai==1.78.0) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai==1.78.0) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.78.0) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.78.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.78.0) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.78.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.78.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.78.0) (0.4.0)\n",
            "Downloading openai-1.78.0-py3-none-any.whl (680 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.4/680.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.76.2\n",
            "    Uninstalling openai-1.76.2:\n",
            "      Successfully uninstalled openai-1.76.2\n",
            "Successfully installed openai-1.78.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.78.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5faf8051-0fc4-4dae-89bd-5682fc6d966f",
      "metadata": {
        "id": "5faf8051-0fc4-4dae-89bd-5682fc6d966f"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "import json\n",
        "from utils import load_prompts\n",
        "prompts = load_prompts(\"prompts.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oS1FH10FBGUD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oS1FH10FBGUD",
        "outputId": "4ab35908-3fff-4fb8-ea63-1fdcabeac1a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "dict_keys(['system', 'user', 'mutual'])\n",
            "Prompts 的內容: \n",
            "========== 現在 key 是 system ==========\n",
            "system['general'] = You are an expert at Natural Language Inference (NLI). Your task is to analyze two pieces of text - a premise and a hypothesis - and classify them into NEUTRAL, ENTAILMENT, or CONTRADICTION.\n",
            "========== 現在 key 是 user ==========\n",
            "user['general'] = premise: {PREMISE_HERE}, hypothesis: {HYPOTHESIS_HERE}.\n",
            "user['json_mode'] = Generate the classification result in JSON with the key: 'result': str (NEUTRAL, ENTAILMENT, or CONTRADICTION)\n",
            "user['few'] = USER: premise: {PREMISE_1}, hypothesis: {HYPOTHESIS_1}.\n",
            "MODEL: {RESULT_1}\n",
            "USER: premise: {PREMISE_2}, hypothesis: {HYPOTHESIS_2}.\n",
            "MODEL: {RESULT_2}\n",
            "USER: premise: {PREMISE_3}, hypothesis: {HYPOTHESIS_3}.\n",
            "MODEL:\n",
            "========== 現在 key 是 mutual ==========\n",
            "mutual['few_hint'] = Please first check the following examples.\n"
          ]
        }
      ],
      "source": [
        "print(type(prompts))\n",
        "print(prompts.keys())\n",
        "print(\"Prompts 的內容: \")\n",
        "for outer_k in prompts.keys():\n",
        "    print(f\"========== 現在 key 是 {outer_k} ==========\")\n",
        "    for inner_k in prompts[outer_k].keys():\n",
        "        print(f\"{outer_k}['{inner_k}'] = {prompts[outer_k][inner_k]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e607cf57-ae84-4360-bfc5-d0bfeb704189",
      "metadata": {
        "id": "e607cf57-ae84-4360-bfc5-d0bfeb704189"
      },
      "outputs": [],
      "source": [
        "MY_openai_KEY = \"API_KEY\"\n",
        "client = OpenAI(api_key=MY_openai_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HfuY879vMQvW",
      "metadata": {
        "id": "HfuY879vMQvW"
      },
      "source": [
        "### 常見 OpenAI 模型與價格\n",
        "- 更詳細的資訊 -> https://platform.openai.com/docs/pricing\n",
        "- Price per 1M tokens\n",
        "\n",
        "| Model                   | Input   | Cached Input | Output   |\n",
        "| ----------------------- | ------- | ------------ | -------- |\n",
        "| gpt-4.1                 | \\$2.00  | \\$0.50       | \\$8.00   |\n",
        "| gpt-4.1-mini            | \\$0.40  | \\$0.10       | \\$1.60   |\n",
        "| gpt-4.1-nano            | \\$0.10  | \\$0.025      | \\$0.40   |\n",
        "| gpt-4.5-preview         | \\$75.00 | \\$37.50      | \\$150.00 |\n",
        "| gpt-4o                  | \\$2.50  | \\$1.25       | \\$10.00  |\n",
        "| gpt-4o-realtime-preview | \\$5.00  | \\$2.50       | \\$20.00  |\n",
        "| gpt-4o-mini             | \\$0.15  | \\$0.075      | \\$0.60   |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "021eccf5-d9bd-4cb8-94e6-19875dfb65a5",
      "metadata": {
        "id": "021eccf5-d9bd-4cb8-94e6-19875dfb65a5"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"gpt-4.1-mini\"\n",
        "TEMPERATURE = 0\n",
        "MAX_GEN_TOKENS = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b9c5331-b062-4b9c-b52e-e1ffd87b2aea",
      "metadata": {
        "id": "3b9c5331-b062-4b9c-b52e-e1ffd87b2aea"
      },
      "outputs": [],
      "source": [
        "system_prompt = prompts[\"system\"][\"general\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "339718ec-0b94-440b-b394-1195890aebe4",
      "metadata": {
        "id": "339718ec-0b94-440b-b394-1195890aebe4"
      },
      "outputs": [],
      "source": [
        "user_prompt_for_json = prompts[\"user\"][\"general\"] + \" \" + prompts[\"user\"][\"json_mode\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f78cca64-ef10-4de8-ae06-fb5d31ac95da",
      "metadata": {
        "id": "f78cca64-ef10-4de8-ae06-fb5d31ac95da"
      },
      "outputs": [],
      "source": [
        "inputs = {\n",
        "    \"premise\": \"A group of kids is playing in a yard and an old man is standing in the background\",\n",
        "    \"hypothesis\": \"A group of boys in a yard is playing and a man is standing in the background\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39021c21-8b43-45b2-8501-0de210687b7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39021c21-8b43-45b2-8501-0de210687b7c",
        "outputId": "a85c3d79-1305-45ee-b1a1-6449de317cdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "premise: A group of kids is playing in a yard and an old man is standing in the background, hypothesis: A group of boys in a yard is playing and a man is standing in the background. Generate the classification result in JSON with the key: 'result': str (NEUTRAL, ENTAILMENT, or CONTRADICTION)\n"
          ]
        }
      ],
      "source": [
        "cur_user_prompt = user_prompt_for_json.format(\n",
        "    PREMISE_HERE=inputs[\"premise\"],\n",
        "    HYPOTHESIS_HERE=inputs[\"hypothesis\"]\n",
        ")\n",
        "print(cur_user_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0zC2pQJcM15v",
      "metadata": {
        "id": "0zC2pQJcM15v"
      },
      "source": [
        "### JSON 生成模式 (JSON mode)\n",
        "- 生成的內容結構化，容易收集特定輸出"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3da88401-fb14-45c2-81c5-6164cf9fbab1",
      "metadata": {
        "id": "3da88401-fb14-45c2-81c5-6164cf9fbab1"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    response_format={\"type\": \"json_object\"},\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": cur_user_prompt},\n",
        "        # 其實是可以接著加進去更多內容\n",
        "    ],\n",
        "    temperature=TEMPERATURE,\n",
        "    max_completion_tokens=MAX_GEN_TOKENS, # 以前這個參數叫做 `max_tokens`\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GP5_YI63ES7o",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP5_YI63ES7o",
        "outputId": "8ed2c05a-19be-4b73-9c90-a237e38437ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatCompletion(id='chatcmpl-BW3LzCt1vBjmuWuDMhkHCQktVGRFF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n  \"result\": \"ENTAILMENT\"\\n}', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1746979087, model='gpt-4.1-mini-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_38647f5e19', usage=CompletionUsage(completion_tokens=12, prompt_tokens=127, total_tokens=139, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EQW2GuYFE0O-",
      "metadata": {
        "id": "EQW2GuYFE0O-"
      },
      "source": [
        "### OpenAI API Output - Organized Format\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"id\": \"chatcmpl-BW3LzCt1vBjmuWuDMhkHCQktVGRFF\",\n",
        "  \"object\": \"chat.completion\",\n",
        "  \"created\": 1746979087,\n",
        "  \"model\": \"gpt-4.1-mini-2025-04-14\",\n",
        "  \"service_tier\": \"default\",\n",
        "  \"system_fingerprint\": \"fp_38647f5e19\",\n",
        "  \"usage\": {\n",
        "    \"prompt_tokens\": 127,\n",
        "    \"completion_tokens\": 12,\n",
        "    \"total_tokens\": 139,\n",
        "    \"prompt_tokens_details\": {\n",
        "      \"audio_tokens\": 0,\n",
        "      \"cached_tokens\": 0\n",
        "    },\n",
        "    \"completion_tokens_details\": {\n",
        "      \"accepted_prediction_tokens\": 0,\n",
        "      \"audio_tokens\": 0,\n",
        "      \"reasoning_tokens\": 0,\n",
        "      \"rejected_prediction_tokens\": 0\n",
        "    }\n",
        "  },\n",
        "  \"choices\": [\n",
        "    {\n",
        "      \"index\": 0,\n",
        "      \"message\": {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"{\\n  \\\"result\\\": \\\"ENTAILMENT\\\"\\n}\",\n",
        "        \"annotations\": [],\n",
        "        \"refusal\": null,\n",
        "        \"audio\": null,\n",
        "        \"function_call\": null,\n",
        "        \"tool_calls\": null\n",
        "      },\n",
        "      \"logprobs\": null,\n",
        "      \"finish_reason\": \"stop\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "asdp0IfIEU5B",
      "metadata": {
        "id": "asdp0IfIEU5B"
      },
      "outputs": [],
      "source": [
        "result_json = json.loads(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf8de3b4-d2ea-436d-9cec-0642447f1ba6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf8de3b4-d2ea-436d-9cec-0642447f1ba6",
        "outputId": "1d1ea86f-12ef-42cb-9c13-d3b28b46bd86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'result': 'ENTAILMENT'}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_json"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XwuArEbKOqcK",
      "metadata": {
        "id": "XwuArEbKOqcK"
      },
      "source": [
        "#### 查看使用的 tokens 數量 (看自己花多少錢)\n",
        "- 也可以到官方網站儀表板查看 -> https://platform.openai.com/usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e46b154-862e-4e95-a92d-c331deebe3dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e46b154-862e-4e95-a92d-c331deebe3dd",
        "outputId": "cedd96f1-c679-4ae1-ce51-5fc0a8f46352"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num of input tokens 127\n",
            "Num of output tokens 12\n"
          ]
        }
      ],
      "source": [
        "print(f\"Num of input tokens {response.usage.prompt_tokens}\")\n",
        "print(f\"Num of output tokens {response.usage.completion_tokens}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pfHtlJ5iM5p4",
      "metadata": {
        "id": "pfHtlJ5iM5p4"
      },
      "source": [
        "### 一般生成模式\n",
        "- 生成的內容較不結構化，甚至冗長"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jlBT6TcjNKeo",
      "metadata": {
        "id": "jlBT6TcjNKeo"
      },
      "outputs": [],
      "source": [
        "user_prompt = prompts[\"user\"][\"general\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XDi6saJuNE85",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDi6saJuNE85",
        "outputId": "9eb45100-c6a4-47b9-d682-e874593e621f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "premise: A group of kids is playing in a yard and an old man is standing in the background, hypothesis: A group of boys in a yard is playing and a man is standing in the background.\n"
          ]
        }
      ],
      "source": [
        "cur_user_prompt = user_prompt.format(\n",
        "    PREMISE_HERE=inputs[\"premise\"],\n",
        "    HYPOTHESIS_HERE=inputs[\"hypothesis\"]\n",
        ")\n",
        "print(cur_user_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T6rWhXBUM8mg",
      "metadata": {
        "id": "T6rWhXBUM8mg"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": cur_user_prompt},\n",
        "        # 其實是可以接著加進去更多內容\n",
        "    ],\n",
        "    temperature=TEMPERATURE,\n",
        "    max_completion_tokens=MAX_GEN_TOKENS, # 以前這個參數叫做 `max_tokens`\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E1ID9MXiNc3P",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1ID9MXiNc3P",
        "outputId": "80f55613-4e78-4dff-a4bf-2f5ef89a3291"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The premise states: \"A group of kids is playing in a yard and an old man is standing in the background.\"\n",
            "\n",
            "The hypothesis states: \"A group of boys in a yard is playing and a man is standing in the background.\"\n",
            "\n",
            "Analysis:\n",
            "- \"A group of kids\" vs. \"A group of boys\": \"Kids\" is a more general term that includes boys and girls, while \"boys\" specifies only male children. The hypothesis narrows the group to boys only, which is not\n"
          ]
        }
      ],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b32e982a-21d7-4148-85d8-e0144f223830",
      "metadata": {
        "id": "b32e982a-21d7-4148-85d8-e0144f223830"
      },
      "source": [
        "## Few-shot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "066491c8-2ab6-477c-907b-10191d915055",
      "metadata": {
        "id": "066491c8-2ab6-477c-907b-10191d915055"
      },
      "outputs": [],
      "source": [
        "fs_system_prompt = prompts[\"system\"][\"general\"] + \" \" + prompts[\"mutual\"][\"few_hint\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b3b910f-055b-46f1-a586-53e9628f6fd8",
      "metadata": {
        "id": "3b3b910f-055b-46f1-a586-53e9628f6fd8"
      },
      "outputs": [],
      "source": [
        "# For OpenAI API, when using response_format={\"type\": \"json_object\"},\n",
        "# we must tell the model to output in JSON in the user prompts.\n",
        "user_prompt = prompts[\"user\"][\"general\"] + \" \" + prompts[\"user\"][\"json_mode\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "231c1b6c-ad68-4fb5-8986-0692508c0905",
      "metadata": {
        "id": "231c1b6c-ad68-4fb5-8986-0692508c0905"
      },
      "outputs": [],
      "source": [
        "few_shot_inputs = [\n",
        "    [\n",
        "        \"A group of kids is playing in a yard and an old man is standing in the background\",\n",
        "        \"A group of boys in a yard is playing and a man is standing in the background\"\n",
        "    ],\n",
        "    [\n",
        "        \"A man, a woman and two girls are walking on the beach\",\n",
        "        \"A group of people is on a beach\"\n",
        "    ],\n",
        "]\n",
        "few_shot_labels = [\"NEUTRAL\", \"ENTAILMENT\"]\n",
        "\n",
        "# inputs without label\n",
        "real_inputs = [\n",
        "        \"Two teams are competing in a football match\",\n",
        "        \"Two groups of people are playing football\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fd980a3-39e7-48a7-8204-e489192d7a9b",
      "metadata": {
        "id": "9fd980a3-39e7-48a7-8204-e489192d7a9b"
      },
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"system\", \"content\": fs_system_prompt}]\n",
        "for sents, label in zip(few_shot_inputs, few_shot_labels):\n",
        "    cur_user_prompt = user_prompt.format(\n",
        "        PREMISE_HERE=sents[0],\n",
        "        HYPOTHESIS_HERE=sents[1]\n",
        "    )\n",
        "    messages.append({\"role\": \"user\", \"content\": cur_user_prompt})\n",
        "    messages.append({\"role\": \"assistant\", \"content\": \"{\"+\"'result': \"+f\"{label}\"+\"}\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12eee8d7-3c34-463c-b268-da2364c2809c",
      "metadata": {
        "id": "12eee8d7-3c34-463c-b268-da2364c2809c"
      },
      "outputs": [],
      "source": [
        "cur_user_prompt = user_prompt.format(\n",
        "    PREMISE_HERE=real_inputs[0],\n",
        "    HYPOTHESIS_HERE=real_inputs[1]\n",
        ")\n",
        "messages.append({\"role\": \"user\", \"content\": cur_user_prompt})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "119fb4fb-504b-4c3d-89af-9afd7fe80e31",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "119fb4fb-504b-4c3d-89af-9afd7fe80e31",
        "outputId": "f879b326-6595-46ef-ada6-e3733e7598c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': 'You are an expert at Natural Language Inference (NLI). Your task is to analyze two pieces of text - a premise and a hypothesis - and classify them into NEUTRAL, ENTAILMENT, or CONTRADICTION. Please first check the following examples.'},\n",
              " {'role': 'user',\n",
              "  'content': \"premise: A group of kids is playing in a yard and an old man is standing in the background, hypothesis: A group of boys in a yard is playing and a man is standing in the background. Generate the classification result in JSON with the key: 'result': str (NEUTRAL, ENTAILMENT, or CONTRADICTION)\"},\n",
              " {'role': 'assistant', 'content': \"{'result': NEUTRAL}\"},\n",
              " {'role': 'user',\n",
              "  'content': \"premise: A man, a woman and two girls are walking on the beach, hypothesis: A group of people is on a beach. Generate the classification result in JSON with the key: 'result': str (NEUTRAL, ENTAILMENT, or CONTRADICTION)\"},\n",
              " {'role': 'assistant', 'content': \"{'result': ENTAILMENT}\"},\n",
              " {'role': 'user',\n",
              "  'content': \"premise: Two teams are competing in a football match, hypothesis: Two groups of people are playing football. Generate the classification result in JSON with the key: 'result': str (NEUTRAL, ENTAILMENT, or CONTRADICTION)\"}]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8623f4f2-90f8-429c-8ee9-4686e165aa0b",
      "metadata": {
        "id": "8623f4f2-90f8-429c-8ee9-4686e165aa0b"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=MODEL_NAME,\n",
        "    response_format={\"type\": \"json_object\"},\n",
        "    messages=messages,\n",
        "    temperature=TEMPERATURE,\n",
        "    max_completion_tokens=MAX_GEN_TOKENS, # 以前這個參數叫做 `max_tokens`\n",
        ")\n",
        "result_json = json.loads(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1a78124-73dc-4897-97f5-72b996c70918",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1a78124-73dc-4897-97f5-72b996c70918",
        "outputId": "34813793-9468-4ad8-f295-00d372a246b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'result': 'ENTAILMENT'}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "deRZ9Qwx7cmQ",
      "metadata": {
        "id": "deRZ9Qwx7cmQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "3riJjmNcTXSt",
      "metadata": {
        "id": "3riJjmNcTXSt"
      },
      "source": [
        "# Google Cloud (Vertex AI) for Llama Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CE133OhEVSO7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE133OhEVSO7",
        "outputId": "15b4b0f7-cb31-4713-b9f6-b2b700b2f525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai==1.78.0 in /usr/local/lib/python3.11/dist-packages (1.78.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.78.0) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.78.0) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.78.0) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.78.0) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai==1.78.0) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai==1.78.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai==1.78.0) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai==1.78.0) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai==1.78.0) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.78.0) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai==1.78.0) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.78.0) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.78.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.78.0) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai==1.78.0) (0.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==1.78.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "okhHwyyhTbF3",
      "metadata": {
        "id": "okhHwyyhTbF3"
      },
      "outputs": [],
      "source": [
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZgjMrhssTqBj",
      "metadata": {
        "id": "ZgjMrhssTqBj"
      },
      "source": [
        "## 使用 llama3-405b\n",
        "```python\n",
        "LOCATION = \"us-central1\"\n",
        "MODEL_ID = \"meta/llama-3.1-405b-instruct-maas\"\n",
        "vertex_ai_endpoint_url = f\"https://{LOCATION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/openapi/chat/completions?\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Lf-QdmJITjXa",
      "metadata": {
        "id": "Lf-QdmJITjXa"
      },
      "outputs": [],
      "source": [
        "# 設定 Google Cloud 專案資訊\n",
        "PROJECT_ID = \"llama3-405b-459201\"\n",
        "LOCATION = \"us-central1\" # 使用的區域\n",
        "MODEL_ID = \"meta/llama-3.1-405b-instruct-maas\" # 確認最新的模型ID\n",
        "\n",
        "# 設定 Vertex AI 端點 URL\n",
        "# 注意：實際的端點格式可能需要查閱最新文件\n",
        "vertex_ai_endpoint_url = f\"https://{LOCATION}-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/openapi/chat/completions?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x6uyd8YNUAiA",
      "metadata": {
        "id": "x6uyd8YNUAiA"
      },
      "outputs": [],
      "source": [
        "# 先開啟 Google Cloud 終端機\n",
        "# 執行 gcloud auth print-access-token 取得 api key\n",
        "\n",
        "access_token_id = \"MY_API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5coCZpOIUDrw",
      "metadata": {
        "id": "5coCZpOIUDrw"
      },
      "outputs": [],
      "source": [
        "client = openai.OpenAI(\n",
        "    base_url=f\"https://us-central1-aiplatform.googleapis.com/v1/projects/{PROJECT_ID}/locations/us-central1/endpoints/openapi/chat/completions?\",\n",
        "    api_key=access_token_id # 使用 gcloud access token 作為 API 金鑰\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IZbT5HrBTluY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZbT5HrBTluY",
        "outputId": "f893f1a8-23df-47b0-ac25-45384eb96a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "玉山國家公園位於台灣南部，成立於1985年4月10日，是台灣的第三個國家公園，也是台灣最高的國家公園。該公園以玉山為中心，涵蓋南投縣、嘉義縣、高雄市等地區，總面積達1,031平方公里。\n",
            "\n",
            "玉山國家公園以其壯麗的山景、豐富的生態資源和多樣的地質景觀而聞名。其中，玉山主峰海拔3,952公尺，是台灣最高峰，也是東亞第一高峰。除了玉山主峰外，公園內還有多座高山，如玉山南峰、玉山東峰等。\n",
            "\n",
            "公園內的生態資源非常豐富，有許多珍貴的植物和動物物種。其中，包括台灣黑熊、台灣雲豹、台灣獼猴等珍貴動物，以及玉山箭竹、玉山杜鵑等特有植物。\n",
            "\n",
            "玉山國家公園也是台灣原住民的重要文化遺址。公園內有許多原住民部落和遺址，其中包括布農族、鄒族等原住民的傳統領域。\n",
            "\n",
            "除了自然景觀和文化遺址外，玉山國家公園還提供許多遊憩活動，如登山、健行、賞花等。每年3月至5月，公園內的杜鵑花盛開，吸引許多遊客前來賞花。\n",
            "\n",
            "總之，玉山國家公園是台灣最重要的自然景觀之一，也是台灣原住民的重要文化遺址。它以其壯麗的山景、豐富的生態資源和多樣的地質景觀而聞名，是台灣最值得一訪的國家公園之一。\n"
          ]
        }
      ],
      "source": [
        "completion = client.chat.completions.create(\n",
        "    model=MODEL_ID, # 指定 Llama 模型 ID\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"請用繁體中文介紹一下台灣的玉山國家公園\"}\n",
        "    ],\n",
        "    # stream=True # 如果需要即時生成結果\n",
        "    # max_tokens=1024,\n",
        "    temperature=0.0,\n",
        "    # top_p=1.0,\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VkBsIzGgWbjL",
      "metadata": {
        "id": "VkBsIzGgWbjL"
      },
      "source": [
        "## 使用 llama4-marverick\n",
        "```python\n",
        "LOCATION = \"us-east5\"\n",
        "MODEL_ID = \"meta/llama-4-maverick-17b-128e-instruct-maas\"\n",
        "MAAS_ENDPOINT = f\"{LOCATION}-aiplatform.googleapis.com\"\n",
        "vertex_ai_endpoint_url = f\"https://{MAAS_ENDPOINT}/v1beta1/projects/{PROJECT_ID}/locations/{LOCATION}/endpoints/openapi\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KcuAOP9hWoTi",
      "metadata": {
        "id": "KcuAOP9hWoTi"
      },
      "source": [
        "(用法同上方 [`使用 llama3-405b`](https://colab.research.google.com/drive/1cn8yJ2fHVIoH6OHN5xDxyHy7Gv7yKexa#scrollTo=ZgjMrhssTqBj&line=6&uniqifier=1) 的範例)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
