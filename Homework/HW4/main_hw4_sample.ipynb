{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c5b9e718-2242-414a-a214-3893846a7fa9",
      "metadata": {
        "id": "c5b9e718-2242-414a-a214-3893846a7fa9"
      },
      "source": [
        "# Homework 4\n",
        "- 開始寫作業前，若使用 Colab 請先設定使用 GPU!!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. 安裝套件\n",
        "\n",
        "# !pip install torch==2.6.0 --index-url https://download.pytorch.org/whl/cu124\n",
        "# !pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "yjBZJhc3NWx8"
      },
      "id": "yjBZJhc3NWx8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee80bdf9-c6cb-4e0a-83dd-df0535cb49dc",
      "metadata": {
        "id": "ee80bdf9-c6cb-4e0a-83dd-df0535cb49dc"
      },
      "outputs": [],
      "source": [
        "# 1. 載入套件\n",
        "\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "from torchmetrics import SpearmanCorrCoef, Accuracy, F1Score\n",
        "\n",
        "# Hugging Face PEFT\n",
        "from peft import get_peft_model, LoraConfig, TaskType\n",
        "from peft.utils.other import prepare_model_for_kbit_training\n",
        "\n",
        "# 客製化模組\n",
        "from dataset import SemevalDataset\n",
        "from model import MultiLabelModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f93d6a06-7f3a-4882-891a-3b1746ddb675",
      "metadata": {
        "id": "f93d6a06-7f3a-4882-891a-3b1746ddb675"
      },
      "outputs": [],
      "source": [
        "# 2. 設定參數\n",
        "\n",
        "MODEL_NAME = \"microsoft/deberta-large\" # \"bert-base-uncased\"\n",
        "LR = 1e-5\n",
        "NUM_EPOCHS = 3\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "VAL_BATCH_SIZE = 8\n",
        "SAVE_DIR = \"./saved_models/\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not Path(SAVE_DIR).exists():\n",
        "    Path(SAVE_DIR).mkdir(parents=True, exist_ok=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 載入資料集與測試\n",
        "\n",
        "data_sample = SemevalDataset(split=\"train\").data[:3]\n",
        "print(f\"Dataset example: \\n{data_sample[0]} \\n{data_sample[1]} \\n{data_sample[2]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmCavLFnPoMN",
        "outputId": "c7c32b33-8b0b-45d2-9007-05b747e2d8d7"
      },
      "id": "AmCavLFnPoMN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset example: \n",
            "{'sentence_pair_id': 1, 'premise': 'A group of kids is playing in a yard and an old man is standing in the background', 'hypothesis': 'A group of boys in a yard is playing and a man is standing in the background', 'relatedness_score': 4.5, 'entailment_judgment': 0} \n",
            "{'sentence_pair_id': 2, 'premise': 'A group of children is playing in the house and there is no man standing in the background', 'hypothesis': 'A group of kids is playing in a yard and an old man is standing in the background', 'relatedness_score': 3.200000047683716, 'entailment_judgment': 0} \n",
            "{'sentence_pair_id': 3, 'premise': 'The young boys are playing outdoors and the man is smiling nearby', 'hypothesis': 'The kids are playing outdoors near a man with a smile', 'relatedness_score': 4.699999809265137, 'entailment_judgment': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 載入 tokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, cache_dir=\"./cache/\")"
      ],
      "metadata": {
        "id": "RcIYq5AkPvgS"
      },
      "id": "RcIYq5AkPvgS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 將 batch 資料進行整理\n",
        "# 取出每筆資料的 'premise' 和 'hypothesis' 內容\n",
        "# 將內容進行 tokenization 換成 token_ids 後，轉成 tensors\n",
        "# 將 labels 也轉成 tensors\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # TODO1: 完成 collate_fn\n",
        "    # Write your code here\n",
        "    return input_text, labels1, labels2"
      ],
      "metadata": {
        "id": "Mianyqk2PXym"
      },
      "id": "Mianyqk2PXym",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d1a3644-f37a-4233-be8b-7f125da22cac",
      "metadata": {
        "id": "3d1a3644-f37a-4233-be8b-7f125da22cac"
      },
      "outputs": [],
      "source": [
        "# 6. 建立 DataLoader\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    SemevalDataset(split=\"train\"),\n",
        "    collate_fn=collate_fn,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    SemevalDataset(split=\"validation\"),\n",
        "    collate_fn=collate_fn,\n",
        "    batch_size=VAL_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eb70a8d-92ba-4eb3-9b44-d61a2d863642",
      "metadata": {
        "id": "4eb70a8d-92ba-4eb3-9b44-d61a2d863642"
      },
      "outputs": [],
      "source": [
        "# 7. 設置 loss functions\n",
        "# 因為是 multi-output learning\n",
        "# 所以應該要有 2 種 loss functions\n",
        "\n",
        "loss_fn1 = torch.nn.MSELoss()\n",
        "loss_fn2 = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "298dea68-338f-4eaf-9962-19effbf7fe2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "298dea68-338f-4eaf-9962-19effbf7fe2b",
        "outputId": "ec411796-6809-4c5c-94dc-90e0c2844483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# 8. 設置評估指標\n",
        "\n",
        "spc = SpearmanCorrCoef()\n",
        "acc = Accuracy(task=\"multiclass\", num_classes=3)\n",
        "f1 = F1Score(task=\"multiclass\", num_classes=3, average='macro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5068972-d508-4403-8b1d-3ef50da5e6cf",
      "metadata": {
        "id": "e5068972-d508-4403-8b1d-3ef50da5e6cf"
      },
      "outputs": [],
      "source": [
        "# 9. 載入模型，並直接把模型送至 GPU\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = MultiLabelModel(MODEL_NAME).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f20dd905-6a37-41f0-8f4d-ccbffa6745dc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f20dd905-6a37-41f0-8f4d-ccbffa6745dc",
        "outputId": "f88b56f3-3a74-49cf-86ee-1dc7ba27e53b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "可訓練參數數量: 2752512 (0.67%)\n"
          ]
        }
      ],
      "source": [
        "# 10. 配置LoRA\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    r=16,                          # LoRA矩陣的秩\n",
        "    lora_alpha=32,                 # LoRA的縮放參數\n",
        "    lora_dropout=0.1,              # LoRA層的dropout率\n",
        "    bias=\"none\",                   # 是否包含偏置參數\n",
        "    target_modules=[\"query_proj\", \"key_proj\", \"value_proj\", \"output.dense\"],  # 要應用LoRA的模塊\n",
        ")\n",
        "\n",
        "# 為主幹模型做準備\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "# 將模型轉換為PEFT模型\n",
        "model = get_peft_model(model, peft_config)\n",
        "\n",
        "# 只訓練LoRA參數\n",
        "for name, param in model.named_parameters():\n",
        "    if \"lora\" not in name and \"regression_head\" not in name and \"classification_head\" not in name:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# 印出可訓練參數的數量\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"可訓練參數數量: {trainable_params} ({trainable_params/total_params:.2%})\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. 載入模型與 optimizer\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr = LR)"
      ],
      "metadata": {
        "id": "sFUGpaprazmS"
      },
      "id": "sFUGpaprazmS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "752579e4",
      "metadata": {
        "id": "752579e4"
      },
      "outputs": [],
      "source": [
        "# 12. 建立測試函數\n",
        "\n",
        "def do_test(\n",
        "    dataloader,\n",
        "    model,\n",
        "    loss_fn1,\n",
        "    loss_fn2,\n",
        "    mode=\"validation\",\n",
        "    cur_epoch=0,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "):\n",
        "    model.eval()\n",
        "\n",
        "    pbar = tqdm(dataloader)\n",
        "    pbar.set_description(f\"{mode} epoch [{cur_epoch+1}/{NUM_EPOCHS}]\")\n",
        "\n",
        "    pred1 = torch.tensor([])\n",
        "    pred2 = torch.tensor([])\n",
        "    gt1 = torch.tensor([])\n",
        "    gt2 = torch.tensor([])\n",
        "    loss1 = 0\n",
        "    loss2 = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_text, labels1, labels2 in pbar:\n",
        "            outputs1, outputs2 = model(**input_text)\n",
        "\n",
        "            loss1 += loss_fn1(outputs1, labels1).item()\n",
        "            loss2 += loss_fn2(outputs2, labels2).item()\n",
        "\n",
        "            outputs1 = outputs1.squeeze()\n",
        "            outputs2 = torch.argmax(outputs2, dim=-1)\n",
        "            pred1 = torch.cat((pred1, outputs1.to(\"cpu\")), dim=-1)\n",
        "            pred2 = torch.cat((pred2, outputs2.to(\"cpu\")), dim=-1)\n",
        "            gt1 = torch.cat((gt1, labels1.to(\"cpu\")), dim=-1)\n",
        "            gt2 = torch.cat((gt2, labels2.to(\"cpu\")), dim=-1)\n",
        "\n",
        "    print(f\"Spearman Corr: {spc(pred1, gt1)} \\nAccuracy: {acc(pred2, gt2)} \\nF1 Score: {f1(pred2, gt2)}\")\n",
        "    loss1 /= len(dataloader)\n",
        "    loss2 /= len(dataloader)\n",
        "    return loss1, loss2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1db45e56-e331-4b90-9709-6747ad82768c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1db45e56-e331-4b90-9709-6747ad82768c",
        "outputId": "8caf9c46-02d9-4a04-eb0b-59e6898120d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training epoch [1/3]:   0%|          | 0/563 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Training epoch [1/3]: 100%|█████████▉| 562/563 [01:35<00:00,  4.36it/s, loss=2.56]/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Training epoch [1/3]: 100%|██████████| 563/563 [01:36<00:00,  5.85it/s, loss=1.32]\n",
            "validation epoch [1/3]: 100%|██████████| 63/63 [00:06<00:00,  9.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman Corr: 0.19111038744449615 \n",
            "Accuracy: 0.5640000104904175 \n",
            "F1 Score: 0.24040921032428741\n",
            "Model saved to ./saved_models/ep0.ckpt!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training epoch [2/3]: 100%|██████████| 563/563 [01:24<00:00,  6.63it/s, loss=1.41]\n",
            "validation epoch [2/3]: 100%|██████████| 63/63 [00:04<00:00, 13.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman Corr: 0.2858576476573944 \n",
            "Accuracy: 0.6159999966621399 \n",
            "F1 Score: 0.3575589954853058\n",
            "Model saved to ./saved_models/ep1.ckpt!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training epoch [3/3]: 100%|██████████| 563/563 [01:23<00:00,  6.72it/s, loss=1.94]\n",
            "validation epoch [3/3]: 100%|██████████| 63/63 [00:04<00:00, 14.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spearman Corr: 0.3598698377609253 \n",
            "Accuracy: 0.6700000166893005 \n",
            "F1 Score: 0.47290879487991333\n",
            "Model saved to ./saved_models/ep2.ckpt!\n"
          ]
        }
      ],
      "source": [
        "# 13. 開始訓練模型\n",
        "\n",
        "for ep in range(NUM_EPOCHS):\n",
        "    pbar = tqdm(train_loader)\n",
        "    pbar.set_description(f\"Training epoch [{ep+1}/{NUM_EPOCHS}]\")\n",
        "    model.train()\n",
        "    # TODO3: Write the training loop\n",
        "    # Write your code here\n",
        "    # train your model\n",
        "    # clear gradient\n",
        "    # forward pass\n",
        "    # compute loss\n",
        "    # back-propagation\n",
        "    # model optimization\n",
        "\n",
        "    val_loss1, val_loss2 = do_test(\n",
        "        val_loader,\n",
        "        model,\n",
        "        loss_fn1,\n",
        "        loss_fn2,\n",
        "        mode=\"validation\",\n",
        "        cur_epoch=ep,\n",
        "        num_epochs=NUM_EPOCHS,\n",
        "    )\n",
        "    torch.save(model, f'./saved_models/ep{ep}.ckpt')\n",
        "    print(f\"Model saved to {SAVE_DIR}ep{ep}.ckpt!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qvrV1wX3QHVe"
      },
      "id": "qvrV1wX3QHVe",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}