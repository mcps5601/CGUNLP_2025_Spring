{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 2: Topic Classification\n",
        "- Dataset: https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset/"
      ],
      "metadata": {
        "id": "NsskNTsoKe7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 0: Download the dataset and upload to Colab or to your local machine\n",
        "- You should register a Kaggle account to download it.\n",
        "- You should create a folder called `data` and put the downloaded files inside it."
      ],
      "metadata": {
        "id": "nu3C_u4NLD02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part I: Data pre-processing"
      ],
      "metadata": {
        "id": "H4iFlXTWK1hC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "metadata": {
        "id": "d6ix911vL-Rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "use_agnews_title =\n",
        "batch_size =\n",
        "test_batch_size =\n",
        "num_epoch =\n",
        "embedding_dim =\n",
        "hidden_size =\n",
        "dropout_rate =\n",
        "learning_rate ="
      ],
      "metadata": {
        "id": "juFjowGJMS3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNNPPhf_KSyK"
      },
      "outputs": [],
      "source": [
        "def preprocess_agnews(\n",
        "    data_type: str = \"train\",\n",
        "    use_agnews_title: bool = False,\n",
        "    train_size: float = 0.8,\n",
        "    random_state: int = 42,\n",
        ") -> Tuple[list, list] | Tuple[list, list, list, list]:\n",
        "    # Read data\n",
        "    df = pd.read_csv(f\"data/{data_type}.csv\")\n",
        "\n",
        "    if data_type == \"train\":\n",
        "        # TODO1-1: split the validation data from the training data\n",
        "        # TODO1-2: do some data pre-processing for the train/valid set\n",
        "        # Write your code here\n",
        "\n",
        "        return train_text, train_label, val_text, val_label\n",
        "\n",
        "    else: # this part should be for the test set\n",
        "        # TODO1-3: do some data pre-processing for the test set\n",
        "        # Write your code here\n",
        "\n",
        "        return test_text, test_label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_text, train_label, val_text, val_label = preprocess_agnews(\n",
        "    data_type=\"train\",\n",
        "    use_agnews_title=use_agnews_title,\n",
        ")\n",
        "test_text, test_label = preprocess_agnews(\n",
        "    data_type=\"test\",\n",
        "    use_agnews_title=use_agnews_title,\n",
        ")\n",
        "num_labels = len(set(train_label))"
      ],
      "metadata": {
        "id": "T9OlmdZvKbr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {'<pad>':0, '<unk>':1}\n",
        "# TODO2: Build the vocabulary\n",
        "# Write your code here\n"
      ],
      "metadata": {
        "id": "-QFkJgvuNZFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO3-1: Write the torch Dataset\n",
        "\n",
        "class AGNewsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, vocab, tokenizer, lower=True):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.vocab = vocab\n",
        "        self.tokenizer = tokenizer  # TODO3-2. Write in the next block.\n",
        "        self.lower = lower\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Write your code here\n",
        "\n",
        "        return # Two things (both can be tensor) should be returned\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "metadata": {
        "id": "UdYcDUKWNdcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = # TODO3-2: Decide your tokenizer. You can use SpaCy, NLTK, and so on ...\n",
        "\n",
        "train_dataset = AGNewsDataset(train_text, train_label, vocab, tokenizer, lower=True)\n",
        "val_dataset = AGNewsDataset(val_text, val_label, vocab, tokenizer, lower=True)\n",
        "test_dataset = AGNewsDataset(test_text, test_label, vocab, tokenizer, lower=True)"
      ],
      "metadata": {
        "id": "wKLYH7-jOkYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO4: Write the collate function\n",
        "\n",
        "def collate_batch(batch):\n",
        "    # Write your code here\n",
        "\n",
        "    return text, label"
      ],
      "metadata": {
        "id": "k0JjuU10O5y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_batch,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=test_batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_batch,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=test_batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_batch,\n",
        ")"
      ],
      "metadata": {
        "id": "kP6Zn_9mPjV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part II: Build your model\n",
        "- You are restricted to use LSTM only."
      ],
      "metadata": {
        "id": "caeNMASxP9Nr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "metadata": {
        "id": "-00BK9JfR4pE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO5: Write the class for your model\n",
        "\n",
        "class LSTMTextClassifier(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout, padding_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = torch.nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
        "        # Write your code here\n",
        "        # You can adjust anything you want.\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [batch_size, seq_len]\n",
        "        # Write your code here\n",
        "\n",
        "        return logits # model outputs before softmax"
      ],
      "metadata": {
        "id": "IOODHhMQP8d3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = LSTMTextClassifier(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_dim=hidden_size,\n",
        "    output_dim=num_labels,\n",
        "    dropout=dropout_rate,\n",
        "    padding_idx=vocab['<pad>'],\n",
        ").to(device)"
      ],
      "metadata": {
        "id": "0nqZicb9QyMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss() # You should use CrossEntropyLoss for classification.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "gRy-cEk4Q9cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part III: Training"
      ],
      "metadata": {
        "id": "CS2rnSAIRhqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader, model, loss_fn):\n",
        "    \"\"\"定義驗證時的進行流程\n",
        "    Arguments:\n",
        "        - dataloader: 具備 mini-batches 的 dataset，由 PyTorch DataLoader 所建立\n",
        "        - model: 要進行驗證的模型\n",
        "        - loss_fn: loss function\n",
        "    Returns:\n",
        "        - loss: 模型在驗證/測試集的 loss\n",
        "        - acc: 模型在驗證/測試集的正確率\n",
        "    \"\"\"\n",
        "    # 設定模型的驗證模式\n",
        "    # 此時 dropout 會自動關閉\n",
        "    model.eval()\n",
        "\n",
        "    # 設定現在不計算梯度\n",
        "    with torch.no_grad():\n",
        "        # 把每個 batch 的 label 儲存成一維 tensor\n",
        "        y_true = torch.tensor([])\n",
        "        y_pred = torch.tensor([])\n",
        "\n",
        "        # 從 dataloader 一次一次抽\n",
        "        for x, y in dataloader:\n",
        "            # 把正確的 label concat 起來\n",
        "            y_true = torch.cat([y_true, y])\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "\n",
        "            logits = model(x)\n",
        "            # 預測的數值大於 0.5 則視為類別1，反之為類別0\n",
        "            pred = torch.argmax(logits, dim=-1)\n",
        "            # 把預測的 label concat 起來\n",
        "            # 注意: 如果使用 gpu 計算的話，要先用 .cpu 把 tensor 轉回 cpu\n",
        "            y_pred = torch.cat([y_pred, pred.cpu()])\n",
        "\n",
        "    # 模型輸出的維度是 (B, 1)，使用.squeeze(-1)可以讓維度變 (B,)\n",
        "    loss = loss_fn(y_pred.squeeze(-1), y_true)\n",
        "    # 計算正確率\n",
        "    acc = accuracy_score(y_true, y_pred.squeeze(-1))\n",
        "    f1 = f1_score(y_true, y_pred.squeeze(-1))\n",
        "\n",
        "    return loss, acc, f1"
      ],
      "metadata": {
        "id": "k_XndOPNRegU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO6: Write the training script\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epoch}\")\n",
        "    for x, y in progress_bar:\n",
        "        # Write your code here\n",
        "\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Write your code here for evaluating your model on the validation data"
      ],
      "metadata": {
        "id": "1MoBAXlFRkFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part IV: Evaluation"
      ],
      "metadata": {
        "id": "l2fqxvn2RtJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 計算測試集的正確率\n",
        "test_loss, test_acc, test_f1 = evaluate(test_loader, model, loss_fn)\n",
        "print(f\"Test Loss: {test_loss}, Test Acc: {test_acc}, Test F1: {test_f1}\")"
      ],
      "metadata": {
        "id": "7WZuQWa_SqhE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}